{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Is1th3sXsLqf"
      },
      "source": [
        "# World Data League 2022"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "JeP6xkRIBJco"
      },
      "source": [
        "## Notebook Submission Template\n",
        "\n",
        "This notebook is one of the mandatory deliverables when you submit your solution. Its structure follows the WDL evaluation criteria and it has dedicated cells where you should add information. Make sure your code is readable as it will be the only technical support the jury will have to evaluate your work. Make sure to list all the datasets used besides the ones provided.\n",
        "\n",
        "Instructions:\n",
        "1. 🧱 Create a separate copy of this template and **do not change** the predefined structure\n",
        "2. 👥 Fill in the Authors section with the name of each team member\n",
        "3. 💻 Develop your code - make sure to add comments and save all the output you want the jury to see. Your code **must be** runnable!\n",
        "4. 📄 Fill in all the text sections\n",
        "5. 🗑️ Remove this section (‘Notebook Submission Template’) and any instructions inside other sections\n",
        "6. 📥 Export as HTML and make sure all the visualisations are visible.\n",
        "7. ⬆️ Upload the .ipynb file to the submission platform and make sure that all the visualisations are visible and everything (text, images, ..) in all deliverables renders correctly.\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "94NlB4NxwLra"
      },
      "source": [
        "## 🎯 Challenge\n",
        "*Insert challenge name here*\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "jVBl_rp5gAdK"
      },
      "source": [
        "## Team: (Insert Team Name Here)\n",
        "## 👥 Authors\n",
        "* Person 1\n",
        "* Person 2\n",
        "* Person 3"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "C8rCpNajszur"
      },
      "source": [
        "## 💻 Development\n",
        "Start coding here! 🐱‍🏍\n",
        "\n",
        "Create the necessary subsections (e.g. EDA, different experiments, etc..) and markdown cells to include descriptions of your work where you see fit. Comment your code. \n",
        "\n",
        "All new subsections must start with three hash characters. More specifically, don't forget to explore the following:\n",
        "1. Assess the data quality\n",
        "2. Make sure you have a good EDA where you enlist all the insights\n",
        "3. Explain the process for feature engineering and cleaning\n",
        "4. Discuss the model / technique(s) selection\n",
        "5. Don't forget to explore model interpretability and fairness or justify why it is not needed\n",
        "\n",
        "Pro-tip 1: Don't forget to make the jury's life easier. Remove any unnecessary prints before submitting the work. Hide any long output cells (from training a model for example). For each subsection, have a quick introduction (justifying what you are about to do) and conclusion (results you got from what you did). \n",
        "\n",
        "Pro-tip 2: Have many similiar graphs which all tell the same story? Add them to the appendix and show only a couple of examples, with the mention that all the others are in the appendix.\n",
        "\n",
        "Pro-tip 3: Don't forget to have a motivate all of your choices, these can be: Data-driven, constraints-driven, literature-driven or a combination of any. For example, why did you choose to test certain algorithms or why only one."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "afB4W0KnutpV"
      },
      "outputs": [],
      "source": [
        "#Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import datetime\n",
        "import seaborn as sns\n",
        "from scipy import stats as st\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px\n",
        "\n",
        "#Preprocessing\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "# Modeling & Metrics\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Load the Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J4jPpcKOutZ5"
      },
      "outputs": [],
      "source": [
        "# Species data\n",
        "df = pd.read_csv('../data/all_species.csv')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Data Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LQ90XveiBN6A"
      },
      "outputs": [],
      "source": [
        "df['Datetime'] = df['Datetime'].astype('datetime64[ns]')\n",
        "df[\"Weather Condition\"].replace(to_replace=\"Sunny and Windy\", value=\"Sunny\", inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "numeric_features = ['Tide', 'Water temperature (ºC)', 'Sessile Coverage']\n",
        "numeric_transformer = Pipeline(\n",
        "    steps=[(\"imputer\", SimpleImputer(strategy=\"median\")), \n",
        "           (\"scaler\", StandardScaler())]\n",
        ")\n",
        "\n",
        "datetime_features = ['Month', 'Year']\n",
        "categorical_features = ['Weather Condition', 'Zone']\n",
        "categorical_transformer = Pipeline(\n",
        "    steps=[\n",
        "        ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
        "        (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\")),\n",
        "    ]\n",
        ")\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"num\", numeric_transformer, numeric_features),\n",
        "        (\"cat\", categorical_transformer, categorical_features + datetime_features),\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Temporal Split for training and validation data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'df' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m min_date \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mDatetime\u001b[39m.\u001b[39miloc[\u001b[39m0\u001b[39m] \u001b[39m# 2011-11-28\u001b[39;00m\n\u001b[1;32m      2\u001b[0m max_date \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mDatetime\u001b[39m.\u001b[39miloc[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39m# 2020-11-16\u001b[39;00m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
          ]
        }
      ],
      "source": [
        "# Adapted from https://www.rasgoml.com/feature-engineering-tutorials/scikit-learn-time-series-split\n",
        "\n",
        "min_date = df.Datetime.iloc[0] #2011-11-28\n",
        "max_date = df.Datetime.iloc[-1] #2020-11-16\n",
        "\n",
        "# Cutoff Date: 2016-05-23\n",
        "train_percent = .5\n",
        "time_between = max_date - min_date\n",
        "train_cutoff = min_date + train_percent*time_between\n",
        "\n",
        "# Set index for referencing\n",
        "train_df.set_index('Datetime', inplace=True)\n",
        "test_df.set_index('Datetime', inplace=True)\n",
        "\n",
        "# Set X and y\n",
        "X_train = train_df[numeric_features + categorical_features + datetime_features] #(1318, 7)\n",
        "y_train = train_df['Abundance (ind/m2)'] #(1318,)\n",
        "X_test = test_df[numeric_features + categorical_features + datetime_features] #(561, 7)\n",
        "y_test = test_df['Abundance (ind/m2)'] #(561,)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Random Forest Regressor** "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create the pipeline with preprocessor and random forest regressor\n",
        "forest_pipeline = Pipeline([\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('forest', RandomForestRegressor(random_state = 0))\n",
        "])\n",
        "\n",
        "# Fit the pipeline on the data\n",
        "forest_pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Predict and score\n",
        "forest_y_preds = forest_pipeline.predict(X_test)\n",
        "mse = mean_squared_error(y_test, forest_y_preds)\n",
        "mse"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "gCcVSUTsasBP"
      },
      "source": [
        "## 🖼️ Visualisations\n",
        "Copy here the most important visualizations (graphs, charts, maps, images, etc). You can refer to them in the Executive Summary.\n",
        "\n",
        "Technical note: If not all the visualisations are visible, you can still include them as an image or link - in this case please upload them to your own repository."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Feature Importances**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gwHbv_NctBLh"
      },
      "outputs": [],
      "source": [
        "# Compute importances and standard deviations\n",
        "feature_names = forest_pipeline.named_steps['preprocessor'].get_feature_names_out()\n",
        "importances = forest_pipeline.named_steps['forest'].feature_importances_\n",
        "std = np.std([tree.feature_importances_ for tree in forest_pipeline.named_steps['forest'].estimators_], axis=0)\n",
        "\n",
        "# Load importances into a frame \n",
        "forest_importances = pd.Series(importances, index=feature_names)\n",
        "forest_importances = forest_importances.sort_values(ascending=False)\n",
        "\n",
        "# Plot top 4 importances\n",
        "fig = px.bar(forest_importances[:5], title=\"Feature importances using MDI\")\n",
        "fig.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Compare actual values to predicted values**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create frame for results\n",
        "actual_values = pd.DataFrame(y_test).reset_index()\n",
        "actual_values = actual_values.groupby(actual_values['Datetime'].dt.year).mean()\n",
        "\n",
        "fitted_values = pd.DataFrame(forest_y_preds, columns=['Abundance (ind/m2)'], index=y_test.index).reset_index()\n",
        "fitted_values['Datetime'] = fitted_values['Datetime'].astype('datetime64[ns]')\n",
        "fitted_values = fitted_values.groupby(fitted_values['Datetime'].dt.year).mean()\n",
        "\n",
        "\n",
        "# Create identifiers for merging\n",
        "fitted_values['Type'] = \"Fitted Value\"\n",
        "actual_values['Type'] = \"Actual Value\"\n",
        "\n",
        "# Merge frames\n",
        "results = pd.concat([fitted_values, actual_values])\n",
        "results.reset_index(inplace=True)\n",
        "\n",
        "# Plot results\n",
        "px.line(results, x='Datetime', y='Abundance (ind/m2)', color='Type')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "F2REdi5_rThg"
      },
      "source": [
        "## 👓 References\n",
        "List all of the external links (even if they are already linked above), such as external datasets, papers, blog posts, code repositories and any other materials."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "uLBpGOl5o0ix"
      },
      "source": [
        "## ⏭️ Appendix\n",
        "Add here any code, images or text that you still find relevant, but that was too long to include in the main report. This section is optional.\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Understanding covariates**\n",
        "\n",
        "- Tide does not have a cyclical or seasonal pattern in the graph\n",
        "    - The measure in meters of the low tide. For more information see: https://oceanservice.noaa.gov/education/tutorial_tides/tides01_intro.html\n",
        "- Sea temperature has a seaonsonal patter, is it stationary? Augmented Dickey-Fuller test (ADF Test)\n",
        "- Sessile Coverage needs more exploration in its patterm\n",
        "    - total % covered of the sample with sessile species\n",
        "- Total / Abundence droppped off at the end of 2016, what happened?\n",
        "    - How many individuals of mobile species studied were found in the sample per m2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mot-NqmmpAHI"
      },
      "outputs": [],
      "source": [
        "df_dt = df.set_index('Datetime')\n",
        "df_dt[variables].plot(subplots=True,figsize = (15,15),title=variables);"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Invasive Species Overtime**\n",
        "- Asparagopsis armata has an increase in coverage after the drop in abundence in 2016, is this related?\n",
        "- Cladophora sp. most aggressive invasive species \n",
        "    - 'Where Cladophora becomes a pest is generally where special circumstances cause such drastic overgrowth that algal blooms develop and form floating mats. Typical examples include where hypertrophication or high mortality of rival organisms produce high concentrations of dissolved phosphorus. Extensive floating mats prevent circulation that is necessary for the aeration of deeper water and, by blocking the light, they kill photosynthesising organisms growing beneath. The mats interfere with the fishing industry by clogging nets and preventing the use of lines. Where they wash ashore the masses of rotting material reduce shoreline property values along water bodies such as the Great Lakes in the United States.[4]'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "invasive = ['Asparagopsis armata (tufosa)',\n",
        "            'Asparagopsis armata (adulta)', \n",
        "            'Osmundea pinnatifida',\n",
        "            'Cladophora sp. (limo)',\n",
        "            'Codium sp. (alga verde carnuda)',\n",
        "            'Colpomenia sinuosa (alga bolhas)']\n",
        "\n",
        "df_dt[invasive].plot(subplots=True,figsize=(15,15),title=invasive);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_dt.groupby(by='Weather Condition')['Abundance (ind/m2)'].agg(np.mean).sort_values().plot()\n",
        "df_dt.groupby(by='Cladophora sp. (limo)')[variables].agg(np.mean).plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "month_group = df_dt.groupby(pd.Grouper(freq='M'))\n",
        "month_ts = month_group.agg({'Tide': np.mean,\n",
        "      'Weather Condition':lambda x: st.mode(x,keepdims=False)[0],\n",
        "      'Water temperature (ºC)':np.mean,\n",
        "      'Supratidal/Middle Intertidal':lambda x: st.mode(x,keepdims=False)[0],\n",
        "      'Substrate':lambda x: st.mode(x,keepdims=False)[0],\n",
        "      'Abundance (ind/m2)':np.mean})\n",
        "\n",
        "month_ts.plot()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "C8rCpNajszur"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
